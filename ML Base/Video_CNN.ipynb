{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets.utils import download_url\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as functions\n",
    "import tarfile\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Loading the data onto the system.\n",
    "#Different way of downloading was used due to problems with \n",
    "##class_num = 100\n",
    "#trainset = datasets.CIFAR100(root='./data', train=True, download=True)\n",
    "#testset = datasets.CIFAR100(root='./data', train=False, download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz to ./cifar100.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169168619/169168619 [00:04<00:00, 34266400.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#downloading the dataset\n",
    "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz\"\n",
    "download_url(dataset_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/pj80vz8n2szdkjlb6bm9k7500000gn/T/ipykernel_69227/688925285.py:3: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path='./data')\n"
     ]
    }
   ],
   "source": [
    "# Extract from archive\n",
    "with tarfile.open('./cifar100.tgz', 'r:gz') as tar:\n",
    "    tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the data set into a training and test set\n",
    "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [45000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x39d2b9010>\n",
      "<torch.utils.data.dataset.Subset object at 0x39d2bb1d0>\n"
     ]
    }
   ],
   "source": [
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     figure\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(label)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Desktop/FPGA-ML/Intel Learning/intel/lib/python3.12/site-packages/matplotlib/pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m     sci(__ret)\n\u001b[1;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/Desktop/FPGA-ML/Intel Learning/intel/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Desktop/FPGA-ML/Intel Learning/intel/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FPGA-ML/Intel Learning/intel/lib/python3.12/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FPGA-ML/Intel Learning/intel/lib/python3.12/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the images worked with the previous version of the dataset\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "for i in range(0, 9):\n",
    "    rand = torch.randint(len(trainset), size=(1,)).item()\n",
    "    img, label = trainset[rand]\n",
    "    figure.add_subplot(3, 3, i+1)\n",
    "    plt.title(label)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernal(im, kern):\n",
    "    #created this to just work with a sample tensor to just teach myself how tensors worked in torch, but needed to updated it to take in the images from cifar100\n",
    "    colors, row_img, col_im = im.shape\n",
    "    row_ker, col_ker = kern.shape\n",
    "    row_out, col_out = row_img - row_ker +1, col_im - col_ker +1\n",
    "    out = torch.zeros([row_out, col_out])\n",
    "    for i in range(row_out):\n",
    "        for j in range(col_out):\n",
    "            out[i,j] = torch.sum(im[1,i:i+row_ker,j:j+col_ker] * kern)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[277], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m test_im \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m      6\u001b[0m     [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      7\u001b[0m ],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      8\u001b[0m test_ker \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m     11\u001b[0m     [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m]\n\u001b[1;32m     12\u001b[0m ],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mkernal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_im\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ker\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[276], line 3\u001b[0m, in \u001b[0;36mkernal\u001b[0;34m(im, kern)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernal\u001b[39m(im, kern):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#created this to just work with a sample tensor to just teach myself how tensors worked in torch, but needed to updated it to take in the images from cifar100\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     colors, row_img, col_im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      4\u001b[0m     row_ker, col_ker \u001b[38;5;241m=\u001b[39m kern\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      5\u001b[0m     row_out, col_out \u001b[38;5;241m=\u001b[39m row_img \u001b[38;5;241m-\u001b[39m row_ker \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, col_im \u001b[38;5;241m-\u001b[39m col_ker \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "#testing does not work after the new kernal \n",
    "test_im = torch.tensor([\n",
    "    [1,2,3,5,6],\n",
    "    [5,2,0,8,6],\n",
    "    [5,2,0,9,6],\n",
    "    [6,2,7,5,2]\n",
    "],dtype=torch.float32)\n",
    "test_ker = torch.tensor([\n",
    "    [0,1,2],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "],dtype=torch.float32)\n",
    "kernal(test_im, test_ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[32.1412, 32.2667, 32.4667, 32.6353, 32.6275, 32.4627, 31.8667, 30.3922,\n",
       "         27.8706, 24.3765, 20.7255, 16.9843, 13.8078, 11.6118, 10.7059, 11.1882,\n",
       "         12.5569, 16.9804, 23.2471, 28.5176, 30.9137, 30.9608, 30.8235, 30.6941,\n",
       "         30.6157, 30.5569, 30.4157, 30.2392, 30.1726, 30.1059],\n",
       "        [31.6824, 31.8000, 31.8784, 31.9765, 31.9804, 32.2196, 31.6784, 30.0824,\n",
       "         27.2667, 23.0784, 18.6941, 13.6902,  9.6392,  7.2039,  6.3020,  6.6275,\n",
       "          7.8000, 10.8941, 16.8941, 23.5373, 28.3765, 30.2941, 30.3608, 30.2863,\n",
       "         30.0784, 29.8902, 29.6980, 29.5176, 29.4980, 29.4431],\n",
       "        [31.5255, 31.5412, 31.1843, 30.5529, 29.7059, 29.8980, 30.0863, 30.3216,\n",
       "         29.1647, 25.9529, 21.4000, 15.6353, 11.1098,  8.3804,  7.1725,  6.3098,\n",
       "          5.8863,  7.0235, 10.7843, 16.2196, 20.8980, 23.9804, 25.0314, 25.8118,\n",
       "         26.9451, 28.3569, 29.6353, 30.3569, 30.6392, 30.4627],\n",
       "        [29.7804, 27.9608, 26.5490, 25.2157, 23.0627, 22.4431, 25.0902, 29.6980,\n",
       "         32.5922, 30.9451, 25.9569, 19.7176, 15.0118, 12.3020, 10.6431,  9.1059,\n",
       "          7.3098,  6.3216,  7.1020, 10.1451, 14.2863, 16.6824, 17.3843, 17.1020,\n",
       "         17.8510, 19.4275, 21.2235, 23.3725, 25.7451, 27.7765],\n",
       "        [22.1137, 19.2039, 17.8274, 16.7686, 15.2745, 15.4588, 19.4235, 26.7255,\n",
       "         32.1882, 32.0275, 26.4863, 20.1529, 16.0510, 13.8510, 12.0549, 10.5922,\n",
       "          9.1333,  7.7725,  7.3294,  7.6275, 10.7333, 14.2235, 16.3647, 16.9608,\n",
       "         16.8118, 17.4471, 17.0118, 16.3569, 16.2627, 17.6000],\n",
       "        [14.8039, 13.5882, 13.5373, 12.9412, 11.6275, 12.2588, 15.1216, 21.6039,\n",
       "         27.2980, 27.5922, 22.6706, 17.4392, 14.9373, 13.0863, 10.8863,  9.8706,\n",
       "         10.0863,  9.4588,  8.1843,  6.8824,  7.9412, 10.7333, 13.9255, 16.9216,\n",
       "         18.5412, 19.5529, 18.7608, 16.1020, 12.4745, 10.2549],\n",
       "        [16.4314, 16.1647, 16.6706, 16.1529, 14.0980, 13.9569, 15.8118, 20.7020,\n",
       "         25.7333, 24.8353, 20.3333, 17.1176, 15.9529, 14.5725, 12.0118, 11.0667,\n",
       "         11.7686, 10.6510,  8.4706,  8.1412,  9.6392, 10.9333, 11.2471, 13.0196,\n",
       "         16.3255, 18.7686, 19.1569, 17.2706, 13.5490,  9.8863],\n",
       "        [20.1294, 19.3216, 19.3882, 18.7804, 16.2941, 14.8118, 16.6157, 22.4902,\n",
       "         27.8314, 27.8431, 24.0784, 23.2471, 22.1059, 19.3843, 15.1216, 12.8000,\n",
       "         12.6078, 11.2039, 10.1216, 11.3137, 12.9137, 12.8941, 10.6980,  9.8667,\n",
       "         11.6314, 14.6784, 17.1176, 17.6784, 16.9216, 15.1176],\n",
       "        [20.5922, 20.2745, 20.4980, 20.1451, 17.3333, 14.9843, 17.0000, 23.2667,\n",
       "         27.4627, 28.0510, 25.1451, 24.8510, 23.4980, 19.7490, 15.5216, 12.4745,\n",
       "         11.6471, 11.5529, 12.0078, 12.6196, 11.8235,  9.6706,  7.2980,  6.3804,\n",
       "          7.2392,  9.5647, 12.5922, 15.5373, 17.7961, 18.6078],\n",
       "        [19.6863, 19.6863, 20.0235, 20.3765, 19.4706, 19.8902, 23.2784, 28.3961,\n",
       "         30.6196, 29.3804, 25.5255, 22.1882, 19.0510, 15.1804, 12.4510, 10.4235,\n",
       "         10.5412, 12.1922, 12.9020, 11.1608,  7.6667,  5.0196,  4.1922,  4.1725,\n",
       "          5.1255,  7.6235, 10.8314, 13.7529, 15.6078, 16.3216],\n",
       "        [19.1451, 19.2627, 19.8157, 22.2431, 25.2157, 27.9765, 30.9333, 33.6392,\n",
       "         34.1294, 31.2510, 26.1294, 20.8314, 16.6235, 12.8784,  9.9176,  7.7882,\n",
       "          9.1922, 12.3647, 13.1765,  9.8745,  5.8118,  3.9922,  4.2706,  4.9020,\n",
       "          5.4510,  7.2314, 10.3176, 12.9765, 13.7137, 12.1961],\n",
       "        [16.7843, 17.1255, 19.2941, 25.3961, 31.0902, 33.8824, 33.5412, 33.0902,\n",
       "         33.1451, 31.3608, 28.0392, 23.2471, 18.0196, 13.1373,  8.6000,  6.3882,\n",
       "          8.8863, 12.6784, 13.3804,  9.8039,  6.3412,  5.0314,  5.6275,  6.9373,\n",
       "          7.9176,  8.4667,  9.5922, 11.0706, 11.7490,  9.8980],\n",
       "        [14.7529, 16.6235, 19.1804, 26.0078, 32.2039, 34.1569, 30.3922, 27.7137,\n",
       "         27.7647, 27.8588, 26.2039, 22.2078, 17.7098, 14.1882, 10.0471,  9.8196,\n",
       "         13.2039, 15.9255, 14.8039, 10.3294,  6.9765,  5.2667,  5.8431,  7.7176,\n",
       "          9.3059,  9.4431,  9.1451,  9.5333,  9.8588,  8.7843],\n",
       "        [15.9137, 17.7647, 18.4392, 22.4706, 28.8627, 32.2000, 29.0431, 25.1686,\n",
       "         25.4078, 26.3137, 24.1686, 19.4510, 15.9098, 15.1294, 12.8706, 14.1725,\n",
       "         17.3294, 18.3294, 15.8314, 10.8392,  7.3294,  5.3922,  5.9137,  7.9529,\n",
       "          9.3451,  8.9608,  7.9765,  7.6784,  7.5961,  6.9294],\n",
       "        [15.5137, 16.4314, 15.7882, 16.4784, 21.5647, 27.3647, 29.0784, 27.2824,\n",
       "         27.1216, 27.3098, 24.5294, 19.5922, 16.0706, 15.2392, 12.7216, 14.4078,\n",
       "         18.1059, 19.0039, 16.3020, 11.6196,  8.1843,  6.4941,  6.9412,  8.5059,\n",
       "          8.9608,  7.7137,  6.2392,  5.4431,  5.2863,  4.9882],\n",
       "        [13.0078, 13.5608, 13.1608, 12.2510, 14.0549, 19.1176, 25.3882, 29.1608,\n",
       "         30.8588, 29.9020, 25.5765, 20.5804, 16.8431, 15.1137, 12.1020, 15.0784,\n",
       "         21.3137, 23.2863, 19.7216, 13.6000,  9.5059,  7.8549,  8.0314,  8.8549,\n",
       "          8.2588,  6.2784,  4.6745,  4.0902,  4.0275,  3.7647],\n",
       "        [11.0157, 11.2706, 11.2353, 10.7490, 11.1255, 13.6706, 19.9843, 27.4235,\n",
       "         32.6941, 32.8510, 27.1686, 21.0863, 17.0902, 15.4941, 13.3686, 15.7882,\n",
       "         21.2902, 23.0431, 20.2863, 15.0118, 11.0392,  8.9176,  8.5373,  8.4824,\n",
       "          7.0784,  4.7059,  3.3373,  3.1059,  3.2000,  3.1137],\n",
       "        [10.7529, 10.8314, 10.8118, 10.6706, 10.6314, 11.1216, 14.4745, 22.3020,\n",
       "         30.0314, 33.1098, 28.1726, 21.2275, 17.0000, 15.7490, 14.6745, 14.0392,\n",
       "         15.3412, 16.0235, 16.0588, 14.6471, 12.2275,  9.9804,  8.9686,  7.6745,\n",
       "          5.5725,  3.3765,  2.5059,  2.6078,  2.8000,  2.8118],\n",
       "        [12.0157, 11.4510, 11.1294, 10.9569, 10.5412,  9.9059, 10.1255, 14.8471,\n",
       "         23.2157, 29.0471, 27.3255, 20.8118, 16.3529, 15.2431, 14.9451, 12.7490,\n",
       "         11.3686, 11.7098, 13.2000, 13.9098, 12.5373, 10.5020,  8.8353,  6.5020,\n",
       "          4.0196,  2.3020,  1.9765,  2.1843,  2.3922,  2.4549],\n",
       "        [11.7765, 10.8314, 10.1216,  9.5412,  9.0235,  8.4745,  7.6667,  8.5608,\n",
       "         14.6314, 21.9882, 24.3922, 20.7255, 16.3333, 14.6902, 14.3569, 12.1137,\n",
       "          9.9137, 10.3882, 11.9843, 12.8706, 11.4549,  9.2431,  7.1137,  4.9020,\n",
       "          3.1098,  1.9843,  1.6431,  1.6039,  1.8784,  2.2078],\n",
       "        [10.2000,  9.3216,  8.6549,  8.2000,  7.6667,  6.9137,  5.8627,  5.0706,\n",
       "          8.4588, 15.9569, 21.6706, 22.0745, 18.4471, 15.3373, 13.7765, 11.5490,\n",
       "          9.5255,  9.8706, 11.0118, 10.9725,  8.8275,  6.7882,  5.4235,  4.3373,\n",
       "          3.2275,  2.1098,  1.5765,  1.5765,  2.1922,  3.1020],\n",
       "        [14.3216, 13.2941, 11.8039, 10.7176, 10.1098,  9.8627,  9.2588,  7.8627,\n",
       "          8.3922, 14.4353, 21.6784, 24.9059, 21.7333, 16.9373, 13.5373, 10.7843,\n",
       "          8.0863,  7.0706,  6.9255,  6.6078,  5.7176,  5.7137,  5.9529,  5.4549,\n",
       "          3.9412,  2.2471,  1.5176,  1.9059,  3.0902,  4.2745],\n",
       "        [17.8078, 15.9333, 13.7333, 13.0706, 14.1686, 16.0196, 17.0549, 15.9608,\n",
       "         14.5529, 16.8235, 22.3765, 24.4510, 20.5490, 14.7020, 10.6314,  7.8824,\n",
       "          5.0588,  3.5333,  3.1608,  3.6706,  4.5608,  6.2549,  7.3647,  6.8196,\n",
       "          4.7490,  2.6078,  1.7216,  2.0039,  2.8941,  3.5961],\n",
       "        [14.8745, 12.8275, 11.5490, 11.9255, 14.4745, 17.6784, 19.6471, 19.3176,\n",
       "         17.9765, 17.6784, 21.1765, 20.5725, 16.1804, 10.2549,  6.8863,  4.9059,\n",
       "          2.7255,  2.0196,  2.8235,  4.2902,  5.6745,  7.1098,  7.8118,  7.1529,\n",
       "          5.0275,  2.8510,  1.8510,  1.9529,  2.4941,  2.8078],\n",
       "        [14.9176, 11.4000,  9.3961,  9.5765, 11.6353, 13.7059, 15.3882, 16.3765,\n",
       "         15.4353, 14.3961, 17.6157, 17.0627, 13.1843,  7.7765,  5.0235,  3.6745,\n",
       "          1.9686,  1.9843,  3.7922,  5.7608,  6.7294,  7.1843,  7.2863,  6.7059,\n",
       "          4.8627,  2.8902,  2.0000,  2.1647,  2.6235,  2.8000],\n",
       "        [15.8902, 12.7922, 10.6157,  9.9451,  9.7922,  9.1059,  8.8510,  9.8039,\n",
       "          9.3882,  9.8196, 14.3137, 14.9647, 11.4353,  6.5529,  3.9490,  2.9412,\n",
       "          1.7294,  2.3333,  4.3922,  6.0706,  6.4235,  6.4471,  6.4235,  6.0745,\n",
       "          4.7059,  2.9529,  2.7176,  3.9725,  4.8549,  4.5020],\n",
       "        [15.4980, 13.6784, 12.4000, 11.8667, 10.6235,  8.3412,  6.0431,  5.1725,\n",
       "          4.7412,  6.7216, 12.0941, 13.2745,  9.9255,  5.5333,  3.1020,  2.3137,\n",
       "          1.8118,  2.9059,  4.8784,  5.8980,  5.7725,  5.6039,  5.5569,  5.3255,\n",
       "          4.4588,  3.0588,  3.1373,  5.1216,  7.4314,  7.9137],\n",
       "        [15.3098, 14.2314, 12.9216, 11.8627, 10.9490,  9.0902,  6.4392,  4.1843,\n",
       "          3.3569,  5.4706, 10.7686, 12.3176,  9.3176,  5.0314,  2.5216,  1.9098,\n",
       "          2.1412,  3.5529,  5.2353,  5.6784,  5.2706,  4.9137,  4.9529,  4.8941,\n",
       "          4.3765,  3.0784,  2.6118,  3.8314,  6.0353,  6.9569],\n",
       "        [12.7961, 12.6314, 11.4353,  9.2000,  8.3255,  7.0000,  5.3176,  3.2431,\n",
       "          2.3569,  4.3843, 10.2471, 12.3765,  9.3412,  4.2471,  1.2784,  0.8784,\n",
       "          1.7294,  3.3294,  4.5882,  4.5451,  3.8824,  3.4745,  3.6431,  3.6863,\n",
       "          3.3294,  2.2627,  1.5647,  1.7765,  2.6784,  3.1059],\n",
       "        [14.0275, 14.8275, 14.5137, 12.4039, 11.4118, 10.6157,  9.9216,  8.9490,\n",
       "          8.5647, 10.2392, 15.5569, 17.5882, 14.8588, 10.2431,  7.5569,  7.3804,\n",
       "          8.2353,  9.5373, 10.2275,  9.8902,  9.3020,  9.1255,  9.2941,  9.2941,\n",
       "          8.9294,  8.3373,  8.0314,  8.1608,  8.5137,  8.5294]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = testset[5]\n",
    "#a kernal test with just one of the images and one its colors\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "print(img.shape)\n",
    "kernal(img,test_ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar100_model():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ##nn.Dropout(0.4),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ##nn.Dropout(0.4),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ##nn.Dropout(0.4),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(0,-1),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "    def forward(self,imgin):\n",
    "        return self.nn(imgin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([3, 32, 32])\n",
      "out.shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "model_1 = Cifar100_model()\n",
    "for images, labels in trainset:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model_1.nn(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, epochs, learning_rate, train_set, test_set):\n",
    "    a = torch.ones(100)\n",
    "    #print(a)\n",
    "    labels = torch.diag(a,0)\n",
    "    #print(labels)\n",
    "    losses = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        m = 0.0\n",
    "        cor_t = 0.0\n",
    "        for j in train_set: ##Training\n",
    "            optimizer.zero_grad() #zeroing out the grad for this training\n",
    "            img, lab = j\n",
    "            lab_r = labels[lab]\n",
    "            ret = model(img)\n",
    "            loss = functions.cross_entropy(ret,lab_r) #\n",
    "            loss.backward()\n",
    "            optimizer.step() #training \n",
    "            optimizer.zero_grad()\n",
    "            if m % 3000 == 0: ##printing so that I know the speed\n",
    "                print(m,end=', ')\n",
    "            m+=1\n",
    "            max = ret[0]\n",
    "            index = 0\n",
    "            for q in range(100): #getting the percent correct \n",
    "                if ret[q] > max:\n",
    "                    index = q\n",
    "                    max = ret[q]\n",
    "            if index == lab:\n",
    "                cor_t += 1\n",
    "            losses.append(loss)\n",
    "        t = 0.\n",
    "        cor = 0.\n",
    "        for k in test_set:\n",
    "            model.eval()\n",
    "            img, lab = k\n",
    "            lab_r = labels[lab]\n",
    "            ret_test = model(img)\n",
    "            loss_test = functions.cross_entropy(ret_test,lab_r) #getting the testing accuracy\n",
    "            if t % 1000 == 0:\n",
    "                print(t,end=', ')\n",
    "            max = ret_test[0]\n",
    "            index = 0\n",
    "            for q in range(100):\n",
    "                if ret_test[q] > max:\n",
    "                    index = q\n",
    "                    max = ret_test[q]\n",
    "            if index == lab:\n",
    "                cor += 1\n",
    "            t+=1\n",
    "        acc = cor/t\n",
    "        acc_t = cor_t/m\n",
    "        print(\"\")\n",
    "        print(\"epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, test_loss: {:.4f}, test_acc: {:.4f}\".format(\n",
    "        i, torch.stack(losses).mean().item(), acc_t, loss_test.detach(), acc))\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "0.0, 3000.0, 6000.0, 9000.0, 12000.0, 15000.0, 18000.0, 21000.0, 24000.0, 27000.0, 30000.0, 33000.0, 36000.0, 39000.0, 42000.0, 0.0, 1000.0, 2000.0, 3000.0, 4000.0, \n",
      "epoch [0], train_loss: 2.8273, train_acc: 0.1172, test_loss: 2.6981, test_acc: 0.1742\n",
      "0.0, 3000.0, 6000.0, 9000.0, 12000.0, 15000.0, 18000.0, 21000.0, 24000.0, 27000.0, 30000.0, 33000.0, 36000.0, 39000.0, 42000.0, 0.0, 1000.0, 2000.0, 3000.0, 4000.0, \n",
      "epoch [1], train_loss: 2.6276, train_acc: 0.2355, test_loss: 3.6809, test_acc: 0.2958\n",
      "0.0, 3000.0, 6000.0, 9000.0, 12000.0, 15000.0, 18000.0, 21000.0, 24000.0, 27000.0, 30000.0, 33000.0, 36000.0, 39000.0, 42000.0, 0.0, 1000.0, 2000.0, 3000.0, 4000.0, \n",
      "epoch [2], train_loss: 2.4896, train_acc: 0.3149, test_loss: 3.9310, test_acc: 0.3330\n",
      "0.0, 3000.0, 6000.0, 9000.0, 12000.0, 15000.0, 18000.0, 21000.0, 24000.0, 27000.0, 30000.0, 33000.0, 36000.0, 39000.0, 42000.0, 0.0, 1000.0, 2000.0, 3000.0, 4000.0, \n",
      "epoch [3], train_loss: 2.3984, train_acc: 0.3451, test_loss: 3.8800, test_acc: 0.3442\n"
     ]
    }
   ],
   "source": [
    "#training the model \n",
    "print(len(trainset))\n",
    "train(model_1.nn, 4, 0.01, trainset, testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|  Modules  | Parameters |\n",
      "+-----------+------------+\n",
      "|  0.weight |    864     |\n",
      "|   0.bias  |     32     |\n",
      "|  3.weight |   18432    |\n",
      "|   3.bias  |     64     |\n",
      "|  6.weight |   36864    |\n",
      "|   6.bias  |     64     |\n",
      "|  9.weight |   36864    |\n",
      "|   9.bias  |     64     |\n",
      "| 12.weight |   73728    |\n",
      "|  12.bias  |    128     |\n",
      "| 16.weight |   32768    |\n",
      "|  16.bias  |    256     |\n",
      "| 18.weight |   65536    |\n",
      "|  18.bias  |    256     |\n",
      "| 20.weight |   25600    |\n",
      "|  20.bias  |    100     |\n",
      "+-----------+------------+\n",
      "Total Trainable Params: 291620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "291620"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code found on https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model_1.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "params = {}\n",
    "for name, param in model_1.nn.named_parameters():\n",
    "    params[name] = param.detach().cpu().numpy().flatten()\n",
    "#print(params)\n",
    "df = pd.DataFrame({ key:pd.Series(value) for key, value in params.items() })\n",
    "df.to_csv('model_params.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
